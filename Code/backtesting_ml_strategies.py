"""
Script: backtesting_ml_strategies.py
Author: Mostafa Shams
Description:
    This script performs a rigorous, peer-review standard backtest of machine learning
    strategies for sports betting, specifically testing the Semi-Strong Efficient Market Hypothesis.

    Methodology:
    1.  Walk-Forward Validation (The "Time Machine"):
        Instead of random shuffling (which causes look-ahead bias), this script uses an
        expanding time window. It starts with an initial training period (e.g., 2000-2006),
        trains the models, and tests them on the subsequent season (2007). It then adds
        the 2007 data to the training set, retrains, and tests on 2008. This process
        repeats until the end of the dataset (2021), simulating exactly how a bettor
        would operate in real-time.

    2.  Models Evaluated:
        - XGBoost (Gradient Boosting)
        - LightGBM (Gradient Boosting)
        - Random Forest (Bagging)
        - Baseline Heuristic: "Bet on Favorite" (Implied Probability > 50%)

    3.  Scientific Metrics & Visualization:
        - Reliability Diagrams (Calibration Curves): To measure model over/underconfidence.
        - Brier Score: To measure probabilistic accuracy (strictly required for forecasting papers).
        - Confusion Matrices: To analyze behavioral biases (e.g., avoiding Draws).
        - Temporal ROI Analysis: A year-over-year breakdown of returns to detect
          market efficiency evolution (alpha decay).

    Input:
        'master_feature_table.csv' (Generated by process_football_data.py)

    Output:
        - 'report_ml_strategies_walk_forward.txt': Comprehensive statistical report.
        - 'fig_calibration_curves.png': Reliability diagrams for all models.
        - 'fig_temporal_roi.png': Line chart of ROI evolution over seasons.
        - 'fig_confusion_matrices.png': Heatmaps of predicted vs actual outcomes.
        - 'fig_bet_distribution.png': Bar chart of betting preferences (Home/Draw/Away).
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, brier_score_loss, confusion_matrix
from sklearn.calibration import calibration_curve
import os
import warnings

warnings.filterwarnings('ignore')

INPUT_FILE = "master_feature_table.csv"
OUTPUT_REPORT = "report_ml_strategies_walk_forward.txt"
INITIAL_BANKROLL = 10000
STAKE = 100

def load_data():
    df = pd.read_csv(INPUT_FILE)
    df['Date'] = pd.to_datetime(df['Date'])
    df = df.sort_values('Date').reset_index(drop=True)
    return df

def get_features_and_target():
    features = [
        'HomeOdds', 'DrawOdds', 'AwayOdds',

        'Home_Avg_Points_L5',
        'Home_Avg_GoalsConceded_L5',
        'Home_Avg_Shots_L5',
        'Home_Avg_ShotsTarget_L5',
        'Home_Avg_Corners_L5',

        'Away_Avg_Points_L5',
        'Away_Avg_GoalsConceded_L5',
        'Away_Avg_Shots_L5',
        'Away_Avg_ShotsTarget_L5',
        'Away_Avg_Corners_L5'
    ]
    target = 'FTR'
    return features, target


def get_models():
    models = {
        'XGBoost': xgb.XGBClassifier(objective='multi:softprob', num_class=3, eval_metric='mlogloss', use_label_encoder=False, random_state=42, n_jobs=-1),
        'LightGBM': lgb.LGBMClassifier(objective='multiclass', num_class=3, random_state=42, n_jobs=-1),
        'RandomForest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
    }
    return models

def calculate_brier_score(y_true, y_prob):
    y_true_onehot = pd.get_dummies(y_true).values
    return np.mean(np.sum((y_prob - y_true_onehot)**2, axis=1))

def run_walk_forward_validation(df, features, target):
    models = get_models()
    le = LabelEncoder()
    df['Target_Encoded'] = le.fit_transform(df[target])
    
    df['Season'] = df['Date'].dt.year
    if df['Date'].dt.month.max() > 7: 
        df['Season'] = np.where(df['Date'].dt.month >= 8, df['Date'].dt.year, df['Date'].dt.year - 1)
    
    seasons = sorted(df['Season'].unique())
    start_season_idx = 5 
    
    results = {name: {'preds': [], 'probs': [], 'actuals': [], 'dates': [], 'odds': [], 'seasons': []} for name in models}
    
    print(f"Starting Walk-Forward Validation across {len(seasons) - start_season_idx} seasons...")

    for i in range(start_season_idx, len(seasons)):
        test_season = seasons[i]
        train_df = df[df['Season'] < test_season]
        test_df = df[df['Season'] == test_season]
        
        X_train = train_df[features]
        y_train = train_df['Target_Encoded']
        X_test = test_df[features]
        y_test = test_df['Target_Encoded']
        
        print(f"  -> Training on seasons {seasons[0]}-{seasons[i-1]} (n={len(train_df)}), Testing on {test_season} (n={len(test_df)})")
        
        for name, model in models.items():
            model.fit(X_train, y_train)
            preds = model.predict(X_test)
            probs = model.predict_proba(X_test)
            
            results[name]['preds'].extend(le.inverse_transform(preds))
            results[name]['probs'].extend(probs)
            results[name]['actuals'].extend(le.inverse_transform(y_test))
            results[name]['dates'].extend(test_df['Date'])
            results[name]['odds'].extend(test_df[['HomeOdds', 'DrawOdds', 'AwayOdds']].values)
            results[name]['seasons'].extend(test_df['Season'])

    return results, le

def analyze_performance(results_dict, le):
    summary_stats = []
    
    for name, data in results_dict.items():
        df_res = pd.DataFrame({
            'Date': data['dates'],
            'Season': data['seasons'],
            'Actual': data['actuals'],
            'Predicted': data['preds']
        })
        
        probs = np.array(data['probs'])
        odds = np.array(data['odds'])
        
        df_res['HomeProb'] = probs[:, 0] 
        df_res['DrawProb'] = probs[:, 1] 
        df_res['AwayProb'] = probs[:, 2] 
        
        classes = le.classes_ 
        mapping = {c: i for i, c in enumerate(classes)}
        
        df_res['HomeProb'] = probs[:, mapping['H']]
        df_res['DrawProb'] = probs[:, mapping['D']]
        df_res['AwayProb'] = probs[:, mapping['A']]
        
        df_res['HomeOdds'] = odds[:, 0] 
        df_res['DrawOdds'] = odds[:, 1]
        df_res['AwayOdds'] = odds[:, 2]
        
        df_res['Bet_Outcome'] = df_res.apply(lambda x: x['Predicted'], axis=1)
        df_res['Bet_Odds'] = df_res.apply(lambda x: x['HomeOdds'] if x['Predicted']=='H' else (x['DrawOdds'] if x['Predicted']=='D' else x['AwayOdds']), axis=1)
        
        df_res['Won'] = df_res['Predicted'] == df_res['Actual']
        df_res['PnL'] = np.where(df_res['Won'], STAKE * (df_res['Bet_Odds'] - 1), -STAKE)
        
        total_bets = len(df_res)
        accuracy = accuracy_score(data['actuals'], data['preds'])
        total_pnl = df_res['PnL'].sum()
        roi = (total_pnl / (total_bets * STAKE)) * 100
        
        y_true_indices = [mapping[x] for x in data['actuals']]
        y_true_onehot = np.zeros((len(y_true_indices), 3))
        y_true_onehot[np.arange(len(y_true_indices)), y_true_indices] = 1
        brier = np.mean(np.sum((probs - y_true_onehot)**2, axis=1))
        
        summary_stats.append({
            'Model': name,
            'Accuracy': accuracy,
            'ROI': roi,
            'Total_PnL': total_pnl,
            'Brier_Score': brier,
            'Bets_Placed': total_bets
        })
        
        df_res.to_csv(f"results_{name}.csv", index=False)

    return pd.DataFrame(summary_stats)

def plot_calibration_curves(results_dict, le):
    plt.figure(figsize=(15, 15))
    plt.plot([0, 1], [0, 1], "k:", label="Perfectly Calibrated")
    
    mapping = {c: i for i, c in enumerate(le.classes_)}
    target_class = 'H' 
    idx = mapping[target_class]
    
    for name, data in results_dict.items():
        probs = np.array(data['probs'])[:, idx]
        actuals = np.array([1 if x == target_class else 0 for x in data['actuals']])
        
        fraction_of_positives, mean_predicted_value = calibration_curve(actuals, probs, n_bins=10)
        plt.plot(mean_predicted_value, fraction_of_positives, "s-", label=f"{name} (Home Win)")
        
    plt.ylabel("Fraction of positives (Actual Win Rate)")
    plt.xlabel("Mean predicted value (Confidence)")
    plt.title("Reliability Diagram (Calibration Curve) - Home Wins")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig("fig_calibration_curves.png")
    plt.close()

def plot_temporal_roi(results_dict):
    plt.figure(figsize=(16, 9))
    
    for name, _ in results_dict.items():
        df = pd.read_csv(f"results_{name}.csv")
        seasonal_roi = df.groupby('Season')['PnL'].sum() / (df.groupby('Season')['Date'].count() * STAKE) * 100
        plt.plot(seasonal_roi.index, seasonal_roi.values, marker='o', label=name)
        
    plt.axhline(0, color='black', linestyle='--')
    plt.xlabel("Season")
    plt.ylabel("ROI (%)")
    plt.title("Year-over-Year ROI Evolution (Alpha Decay Analysis)")
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig("fig_temporal_roi.png")
    plt.close()

def plot_confusion_matrices(results_dict, le):
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    classes = le.classes_ 
    
    for i, (name, data) in enumerate(results_dict.items()):
        cm = confusion_matrix(data['actuals'], data['preds'], labels=classes)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i], xticklabels=classes, yticklabels=classes)
        axes[i].set_title(f"{name} Confusion Matrix")
        axes[i].set_xlabel("Predicted")
        axes[i].set_ylabel("Actual")
        
    plt.tight_layout()
    plt.savefig("fig_confusion_matrices.png")
    plt.close()

def plot_bet_distribution(results_dict, le):
    data_list = []
    classes = le.classes_
    
    for name, data in results_dict.items():
        preds = pd.Series(data['preds'])
        dist = preds.value_counts(normalize=True)
        for c in classes:
            data_list.append({'Model': name, 'Outcome': c, 'Percentage': dist.get(c, 0)})
            
    df_dist = pd.DataFrame(data_list)
    
    plt.figure(figsize=(16, 9))
    sns.barplot(x='Model', y='Percentage', hue='Outcome', data=df_dist)
    plt.title("Bet Distribution Analysis (Bias Check)")
    plt.ylabel("Percentage of Bets")
    plt.grid(True, axis='y', alpha=0.3)
    plt.savefig("fig_bet_distribution.png")
    plt.close()

def main():
    print("Author: Mostafa Shams")
    print("Task:   Walk-Forward Validation")

    
    df = load_data()
    features, target = get_features_and_target()
    
    results, le = run_walk_forward_validation(df, features, target)
    
    summary = analyze_performance(results, le)
    
    print("\n--- FINAL PERFORMANCE SUMMARY ---")
    print(summary.to_string(index=False))
    
    with open(OUTPUT_REPORT, "w") as f:
        f.write("WALK-FORWARD VALIDATION REPORT\n")
        f.write(summary.to_string(index=False))
        f.write("\n\n INTERPRETATION OF METRICS:\n")
        f.write(" - Brier Score: Lower is better. Measures calibration accuracy.\n")
        f.write(" - ROI: Return on Investment. Positive indicates profit.\n")
        f.write(" - Accuracy: Percentage of correct outcome predictions.\n")
    
    print("\nGenerating Scientific Visualizations...")
    plot_calibration_curves(results, le)
    plot_temporal_roi(results)
    plot_confusion_matrices(results, le)
    plot_bet_distribution(results, le)
    
    print("Done. All reports and figures generated.")

if __name__ == "__main__":
    main()
